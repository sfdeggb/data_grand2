{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIN 网络的实现与改进"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<string>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;34me:\\360downloads\\lib\\ast.py\u001b[0m, in \u001b[0;32mparse\u001b[0m:\nLine \u001b[0;34m50\u001b[0m:    \u001b[34mreturn\u001b[39;49;00m \u001b[36mcompile\u001b[39;49;00m(source, filename, mode, flags,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[0;31mSyntaxError\u001b[0m: invalid syntax (<string>, line 1)\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install deepcrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIN网络搭建\n",
    "def DIN(feature_columns, behavior_feature_list, behavior_seq_feature_list):\n",
    "    \"\"\"\n",
    "    这里搭建DIN网络，有了上面的各个模块，这里直接拼起来\n",
    "    :param feature_columns: A list. 里面的每个元素是namedtuple(元组的一种扩展类型，同时支持序号和属性名访问组件)类型，表示的是数据的特征封装版\n",
    "    :param behavior_feature_list: A list. 用户的候选行为列表\n",
    "    :param behavior_seq_feature_list: A list. 用户的历史行为列表\n",
    "    \"\"\"\n",
    "    # 构建Input层并将Input层转成列表作为模型的输入\n",
    "    input_layer_dict = build_input_layers(feature_columns)\n",
    "    input_layers = list(input_layer_dict.values())\n",
    "    \n",
    "    # 筛选出特征中的sparse和Dense特征， 后面要单独处理\n",
    "    sparse_feature_columns = list(filter(lambda x: isinstance(x, SparseFeat), feature_columns))\n",
    "    dense_feature_columns = list(filter(lambda x: isinstance(x, DenseFeat), feature_columns))\n",
    "    \n",
    "    # 获取Dense Input\n",
    "    dnn_dense_input = []\n",
    "    for fc in dense_feature_columns:\n",
    "        dnn_dense_input.append(input_layer_dict[fc.name])\n",
    "    \n",
    "    # 将所有的dense特征拼接\n",
    "    dnn_dense_input = concat_input_list(dnn_dense_input)   # (None, dense_fea_nums)\n",
    "    \n",
    "    # 构建embedding字典\n",
    "    embedding_layer_dict = build_embedding_layers(feature_columns, input_layer_dict)\n",
    "\n",
    "    # 离散的这些特特征embedding之后，然后拼接，然后直接作为全连接层Dense的输入，所以需要进行Flatten\n",
    "    dnn_sparse_embed_input = concat_embedding_list(sparse_feature_columns, input_layer_dict, embedding_layer_dict, flatten=True)\n",
    "    \n",
    "    # 将所有的sparse特征embedding特征拼接\n",
    "    dnn_sparse_input = concat_input_list(dnn_sparse_embed_input)   # (None, sparse_fea_nums*embed_dim)\n",
    "    \n",
    "    # 获取当前行为特征的embedding， 这里有可能有多个行为产生了行为列表，所以需要列表将其放在一起\n",
    "    query_embed_list = embedding_lookup(behavior_feature_list, input_layer_dict, embedding_layer_dict)\n",
    "    \n",
    "    # 获取历史行为的embedding， 这里有可能有多个行为产生了行为列表，所以需要列表将其放在一起\n",
    "    keys_embed_list = embedding_lookup(behavior_seq_feature_list, input_layer_dict, embedding_layer_dict)\n",
    "    # 使用注意力机制将历史行为的序列池化，得到用户的兴趣\n",
    "    dnn_seq_input_list = []\n",
    "    for i in range(len(keys_embed_list)):\n",
    "        seq_embed = AttentionPoolingLayer()([query_embed_list[i], keys_embed_list[i]])  # (None, embed_dim)\n",
    "        dnn_seq_input_list.append(seq_embed)\n",
    "    \n",
    "    # 将多个行为序列的embedding进行拼接\n",
    "    dnn_seq_input = concat_input_list(dnn_seq_input_list)  # (None, hist_len*embed_dim)\n",
    "    \n",
    "    # 将dense特征，sparse特征， 即通过注意力机制加权的序列特征拼接起来\n",
    "    dnn_input = Concatenate(axis=1)([dnn_dense_input, dnn_sparse_input, dnn_seq_input]) # (None, dense_fea_num+sparse_fea_nums*embed_dim+hist_len*embed_dim)\n",
    "    \n",
    "    # 获取最终的DNN的预测值\n",
    "    dnn_logits = get_dnn_logits(dnn_input, activation='prelu')\n",
    "    \n",
    "    model = Model(inputs=input_layers, outputs=dnn_logits)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (XPython Raw)",
   "language": "python",
   "name": "xpython-raw"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
