{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    {\"statis_date\": \"20241106\", \"serv_number\": \"13487028369\", \"video_id\": \"45211\", \"env_video_time\": \"38.0\", \"oper_time\": \"2024-11-06 00:32:29\"},\n",
    "    {\"statis_date\": \"20241106\", \"serv_number\": \"13457692971\", \"video_id\": \"44963\", \"env_video_time\": \"38.0\", \"oper_time\": \"2024-11-06 00:32:37\"},\n",
    "    {\"statis_date\": \"20241106\", \"serv_number\": \"13487028369\", \"video_id\": \"48948\", \"env_video_time\": \"100.0\", \"oper_time\": \"2024-11-06 00:47:47\"},\n",
    "    {\"statis_date\": \"20241107\", \"serv_number\": \"13548466410\", \"video_id\": \"48082\", \"env_video_time\": \"72.0\", \"oper_time\": \"2024-11-07 00:23:46\"},\n",
    "    {\"statis_date\": \"20241107\", \"serv_number\": \"13457692971\", \"video_id\": \"44963\", \"env_video_time\": \"0.0\", \"oper_time\": \"2024-11-07 00:24:58\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  statis_date  serv_number video_id env_video_time            oper_time\n",
      "0    20241106  13487028369    45211           38.0  2024-11-06 00:32:29\n",
      "1    20241106  13457692971    44963           38.0  2024-11-06 00:32:37\n",
      "2    20241106  13485401573    48948          100.0  2024-11-06 00:47:47\n",
      "3    20241106  13548466410    48082           72.0  2024-11-06 00:23:46\n",
      "4    20241106  17837240647    44963            0.0  2024-11-06 00:24:58\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 创建DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 显示DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data(df, sample_size=3000000):\n",
    "    \"\"\"\n",
    "    按要求采样数据\n",
    "    Args:\n",
    "        df: 原始DataFrame\n",
    "        sample_size: 目标采样大小，默认300万\n",
    "    Returns:\n",
    "        采样后的DataFrame\n",
    "    \"\"\"\n",
    "    # 确保时间戳格式正确\n",
    "    df['oper_time'] = pd.to_datetime(df['oper_time'], format='mixed')\n",
    "    df['date'] = df['oper_time'].dt.date\n",
    "    \n",
    "    # 将serv_number转换为字符串并确保统一格式\n",
    "    df['serv_number'] = df['serv_number'].astype(str).str.strip()\n",
    "    \n",
    "    # 按手机号和时间排序（使用字符串排序）\n",
    "    df_sorted = df.sort_values(['serv_number', 'oper_time'], \n",
    "                             key=lambda x: x.astype(str) if x.name == 'serv_number' else x)\n",
    "    \n",
    "    # 获取前300万行\n",
    "    sampled = df_sorted.head(sample_size)\n",
    "    \n",
    "    # 获取第300万行的用户和日期\n",
    "    if len(df_sorted) > sample_size:\n",
    "        last_user = sampled.iloc[-1]['serv_number']\n",
    "        last_date = sampled.iloc[-1]['date']\n",
    "        \n",
    "        # 获取最后一个用户当天的所有剩余记录\n",
    "        remaining_records = df_sorted[\n",
    "            (df_sorted['serv_number'] == last_user) & \n",
    "            (df_sorted['date'] == last_date) & \n",
    "            (df_sorted.index > sampled.index[-1])\n",
    "        ]\n",
    "        \n",
    "        # 将剩余记录添加到采样数据中\n",
    "        sampled = pd.concat([sampled, remaining_records])\n",
    "    \n",
    "    return sampled\n",
    "\n",
    "# 使用示例\n",
    "if __name__ == \"__main__\":\n",
    "    # 读取原始数据\n",
    "    df = pd.read_csv('your_data.csv')\n",
    "    \n",
    "    # 查看数据类型\n",
    "    print(\"采样前数据类型：\")\n",
    "    print(df.dtypes)\n",
    "    \n",
    "    # 进行采样\n",
    "    sampled_df = sample_data(df, sample_size=3000000)\n",
    "    \n",
    "    print(f\"\\n原始数据大小: {len(df)}\")\n",
    "    print(f\"采样后数据大小: {len(sampled_df)}\")\n",
    "    \n",
    "    print(\"\\n采样后数据类型：\")\n",
    "    print(sampled_df.dtypes)\n",
    "    \n",
    "    # 保存采样结果\n",
    "    sampled_df.to_csv('sampled_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始处理数据，总数据量: 6 条\n",
      "正在处理时间戳...\n",
      "总共需要处理 2 个用户日期组\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理进度: 100%|██████████████████████████████████████████████████████| 2/2 [00:00<00:00, 460.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "处理完成！总耗时: 0:00:00.025781\n",
      "\n",
      "处理结果示例:\n",
      "  statis_date  serv_number video_id env_video_time               oper_time  \\\n",
      "0    20241106  13487028369    45211           38.0 2024-11-06 00:32:29.130   \n",
      "1    20241106  13487028369    45211           38.0 2024-11-06 00:32:30.130   \n",
      "2    20241106  13487028369    48948          100.0 2024-11-06 00:47:47.000   \n",
      "3    20241107  13548466410    48082           72.0 2024-11-07 00:23:46.269   \n",
      "4    20241107  13548466410    44963            0.0 2024-11-07 00:24:58.000   \n",
      "5    20241107  13548466410    44964            0.0 2024-11-07 00:24:59.000   \n",
      "\n",
      "         date  label  \n",
      "0  2024-11-06      3  \n",
      "1  2024-11-06      2  \n",
      "2  2024-11-06      1  \n",
      "3  2024-11-07      3  \n",
      "4  2024-11-07      2  \n",
      "5  2024-11-07      1  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def generate_watch_count_labels_vectorized(df):\n",
    "    \"\"\"\n",
    "    完全向量化的版本，适用于内存充足的情况\n",
    "    \"\"\"\n",
    "    print(f\"开始处理数据，总数据量: {len(df):,} 条\")\n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    # 确保时间戳格式正确\n",
    "    print(\"正在处理时间戳...\")\n",
    "    df['oper_time'] = pd.to_datetime(df['oper_time'], format='mixed')\n",
    "    df['date'] = df['oper_time'].dt.date\n",
    "    \n",
    "    result = df.copy()\n",
    "    \n",
    "    # 使用apply替代循环\n",
    "    def count_remaining(group):\n",
    "        group = group.sort_values('oper_time')\n",
    "        times = group['oper_time'].values\n",
    "        return np.sum(times.reshape(-1, 1) <= times.reshape(1, -1), axis=1)\n",
    "    \n",
    "    # 获取分组信息并显示\n",
    "    groups = df.groupby(['serv_number', 'date'])\n",
    "    group_count = len(groups)\n",
    "    print(f\"总共需要处理 {group_count:,} 个用户日期组\")\n",
    "    \n",
    "    # 使用tqdm包装groupby的apply操作\n",
    "    tqdm.pandas(desc=\"处理进度\", ncols=100)\n",
    "    result['label'] = groups.progress_apply(\n",
    "        lambda x: pd.Series(count_remaining(x), index=x.index)\n",
    "    ).values\n",
    "    \n",
    "    # 计算总耗时\n",
    "    end_time = datetime.now()\n",
    "    process_time = end_time - start_time\n",
    "    print(f\"\\n处理完成！总耗时: {process_time}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# 示例使用\n",
    "if __name__ == \"__main__\":\n",
    "    # 创建示例数据\n",
    "    data = [\n",
    "        {\"statis_date\": \"20241106\", \"serv_number\": \"13487028369\", \"video_id\": \"45211\", \"env_video_time\": \"38.0\", \"oper_time\": \"2024-11-06 00:32:29.130\"},#2\n",
    "        {\"statis_date\": \"20241106\", \"serv_number\": \"13487028369\", \"video_id\": \"45211\", \"env_video_time\": \"38.0\", \"oper_time\": \"2024-11-06 00:32:30.130\"},#2       \n",
    "        {\"statis_date\": \"20241106\", \"serv_number\": \"13487028369\", \"video_id\": \"48948\", \"env_video_time\": \"100.0\", \"oper_time\": \"2024-11-06 00:47:47\"},#1\n",
    "        {\"statis_date\": \"20241107\", \"serv_number\": \"13548466410\", \"video_id\": \"48082\", \"env_video_time\": \"72.0\", \"oper_time\": \"2024-11-07 00:23:46.269\"},#3\n",
    "        {\"statis_date\": \"20241107\", \"serv_number\": \"13548466410\", \"video_id\": \"44963\", \"env_video_time\": \"0.0\", \"oper_time\": \"2024-11-07 00:24:58\"},#2\n",
    "        {\"statis_date\": \"20241107\", \"serv_number\": \"13548466410\", \"video_id\": \"44964\", \"env_video_time\": \"0.0\", \"oper_time\": \"2024-11-07 00:24:59\"}#1\n",
    "    ]\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # 生成标签\n",
    "    labeled_df = generate_watch_count_labels_vectorized(df)\n",
    "    \n",
    "    print(\"\\n处理结果示例:\")\n",
    "    print(labeled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始处理数据，总数据量: 6 条\n",
      "正在处理时间戳...\n",
      "总共需要处理 2 个用户日期组\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理进度: 100%|██████████████████████████████████████████████████████| 2/2 [00:00<00:00, 217.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "处理完成！总耗时: 0:00:00.068279\n",
      "\n",
      "处理结果示例:\n",
      "  statis_date  serv_number video_id env_video_time               oper_time  \\\n",
      "0    20241106  13487028369    45211           38.0 2024-11-06 00:32:29.130   \n",
      "1    20241106  13487028369    45211           38.0 2024-11-06 00:32:30.130   \n",
      "2    20241106  13487028369    48948          100.0 2024-11-06 00:47:47.000   \n",
      "3    20241107  13548466410    48082           72.0 2024-11-07 00:23:46.269   \n",
      "4    20241107  13548466410    44963            0.0 2024-11-07 00:24:58.000   \n",
      "5    20241107  13548466410    44964            0.0 2024-11-07 00:24:59.000   \n",
      "\n",
      "   env_watch_time        date  label  \n",
      "0             7.0  2024-11-06      2  \n",
      "1             0.0  2024-11-06      1  \n",
      "2             5.0  2024-11-06      1  \n",
      "3             6.0  2024-11-07      2  \n",
      "4             0.0  2024-11-07      1  \n",
      "5             2.0  2024-11-07      1  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def generate_watch_count_labels_vectorized(df):\n",
    "    \"\"\"\n",
    "    完全向量化的版本，排除 env_video_time <= 0 的记录\n",
    "    \"\"\"\n",
    "    print(f\"开始处理数据，总数据量: {len(df):,} 条\")\n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    # 确保时间戳格式正确\n",
    "    print(\"正在处理时间戳...\")\n",
    "    df['oper_time'] = pd.to_datetime(df['oper_time'], format='mixed')\n",
    "    df['date'] = df['oper_time'].dt.date\n",
    "    \n",
    "    # 确保 env_video_time 为数值类型\n",
    "    df['env_watch_time'] = pd.to_numeric(df['env_watch_time'], errors='coerce')\n",
    "    \n",
    "    result = df.copy()\n",
    "    \n",
    "    def count_remaining(group):\n",
    "        group = group.sort_values('oper_time')\n",
    "        times = group['oper_time'].values\n",
    "        # 创建有效观看时长的掩码\n",
    "        valid_mask = group['env_watch_time'].values > 0\n",
    "        # 使用掩码创建计数矩阵\n",
    "        count_matrix = (times.reshape(-1, 1) <= times.reshape(1, -1)) & valid_mask.reshape(1, -1)\n",
    "        return np.sum(count_matrix, axis=1)\n",
    "    \n",
    "    # 获取分组信息并显示\n",
    "    groups = df.groupby(['serv_number', 'date'])\n",
    "    group_count = len(groups)\n",
    "    print(f\"总共需要处理 {group_count:,} 个用户日期组\")\n",
    "    \n",
    "    # 使用tqdm包装groupby的apply操作\n",
    "    tqdm.pandas(desc=\"处理进度\", ncols=100)\n",
    "    result['label'] = groups.progress_apply(\n",
    "        lambda x: pd.Series(count_remaining(x), index=x.index)\n",
    "    ).values\n",
    "    \n",
    "    # 计算总耗时\n",
    "    end_time = datetime.now()\n",
    "    process_time = end_time - start_time\n",
    "    print(f\"\\n处理完成！总耗时: {process_time}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# 示例使用\n",
    "if __name__ == \"__main__\":\n",
    "    # 创建示例数据\n",
    "    data = [\n",
    "        {\"statis_date\": \"20241106\", \"serv_number\": \"13487028369\", \"video_id\": \"45211\", \"env_video_time\": \"38.0\", \"oper_time\": \"2024-11-06 00:32:29.130\",\"env_watch_time\":7.0},#2\n",
    "        {\"statis_date\": \"20241106\", \"serv_number\": \"13487028369\", \"video_id\": \"45211\", \"env_video_time\": \"38.0\", \"oper_time\": \"2024-11-06 00:32:30.130\",\"env_watch_time\":0.0},#2       \n",
    "        {\"statis_date\": \"20241106\", \"serv_number\": \"13487028369\", \"video_id\": \"48948\", \"env_video_time\": \"100.0\", \"oper_time\": \"2024-11-06 00:47:47\",\"env_watch_time\":5.0},#1\n",
    "        {\"statis_date\": \"20241107\", \"serv_number\": \"13548466410\", \"video_id\": \"48082\", \"env_video_time\": \"72.0\", \"oper_time\": \"2024-11-07 00:23:46.269\",\"env_watch_time\":6.0},#3\n",
    "        {\"statis_date\": \"20241107\", \"serv_number\": \"13548466410\", \"video_id\": \"44963\", \"env_video_time\": \"0.0\", \"oper_time\": \"2024-11-07 00:24:58\",\"env_watch_time\":0.0},#2\n",
    "        {\"statis_date\": \"20241107\", \"serv_number\": \"13548466410\", \"video_id\": \"44964\", \"env_video_time\": \"0.0\", \"oper_time\": \"2024-11-07 00:24:59\",\"env_watch_time\":2.0}#1\n",
    "    ]\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # 生成标签\n",
    "    labeled_df = generate_watch_count_labels_vectorized(df)\n",
    "    \n",
    "    print(\"\\n处理结果示例:\")\n",
    "    print(labeled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statis_date</th>\n",
       "      <th>serv_number</th>\n",
       "      <th>video_id</th>\n",
       "      <th>env_video_time</th>\n",
       "      <th>oper_time</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20241106</td>\n",
       "      <td>13487028369</td>\n",
       "      <td>45211</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2024-11-06 00:32:29.130</td>\n",
       "      <td>2024-11-06</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20241106</td>\n",
       "      <td>13457692971</td>\n",
       "      <td>44963</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2024-11-06 00:32:37.000</td>\n",
       "      <td>2024-11-06</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20241106</td>\n",
       "      <td>13487028369</td>\n",
       "      <td>48948</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2024-11-06 00:47:47.000</td>\n",
       "      <td>2024-11-06</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20241107</td>\n",
       "      <td>13548466410</td>\n",
       "      <td>48082</td>\n",
       "      <td>72.0</td>\n",
       "      <td>2024-11-07 00:23:46.269</td>\n",
       "      <td>2024-11-07</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20241107</td>\n",
       "      <td>13548466410</td>\n",
       "      <td>44963</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024-11-07 00:24:58.000</td>\n",
       "      <td>2024-11-07</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20241107</td>\n",
       "      <td>13548466410</td>\n",
       "      <td>44964</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024-11-07 00:24:59.000</td>\n",
       "      <td>2024-11-07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  statis_date  serv_number video_id env_video_time               oper_time  \\\n",
       "0    20241106  13487028369    45211           38.0 2024-11-06 00:32:29.130   \n",
       "1    20241106  13457692971    44963           38.0 2024-11-06 00:32:37.000   \n",
       "2    20241106  13487028369    48948          100.0 2024-11-06 00:47:47.000   \n",
       "3    20241107  13548466410    48082           72.0 2024-11-07 00:23:46.269   \n",
       "4    20241107  13548466410    44963            0.0 2024-11-07 00:24:58.000   \n",
       "5    20241107  13548466410    44964            0.0 2024-11-07 00:24:59.000   \n",
       "\n",
       "         date  label  \n",
       "0  2024-11-06      1  \n",
       "1  2024-11-06      2  \n",
       "2  2024-11-06      1  \n",
       "3  2024-11-07      3  \n",
       "4  2024-11-07      2  \n",
       "5  2024-11-07      1  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "def split_dataframe(df, num_splits=20, save_dir='/data/zhujianhao/split_data'):\n",
    "    \"\"\"\n",
    "    将DataFrame分割为指定数量的子集并保存，确保同一用户的数据不会被分到不同子集\n",
    "    \n",
    "    Args:\n",
    "        df: 已经按serv_number和oper_time排序的DataFrame\n",
    "        num_splits: 需要分割的份数，默认20\n",
    "        save_dir: 保存分割数据的目录路径\n",
    "    \"\"\"\n",
    "    print(f\"开始分割数据集，总数据量: {len(df):,} 条\")\n",
    "    \n",
    "    # 确保保存目录存在\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # 计算理想的每份大小\n",
    "    base_size = len(df) // num_splits\n",
    "    \n",
    "    start_idx = 0\n",
    "    split_info = []  # 用于存储每个分片的信息\n",
    "    \n",
    "    for split_num in tqdm(range(num_splits), desc=\"分割进度\"):\n",
    "        # 生成保存文件路径\n",
    "        save_path = os.path.join(save_dir, f'sample_data_{split_num+1:02d}.csv')\n",
    "        \n",
    "        if split_num == num_splits - 1:\n",
    "            # 最后一份直接取到结束\n",
    "            split_df = df.iloc[start_idx:]\n",
    "            split_df.to_csv(save_path, index=False)\n",
    "            split_info.append({\n",
    "                'split_num': split_num + 1,\n",
    "                'size': len(split_df),\n",
    "                'file_path': save_path\n",
    "            })\n",
    "            break\n",
    "            \n",
    "        # 计算当前分割的理想结束位置\n",
    "        end_idx = start_idx + base_size\n",
    "        \n",
    "        if end_idx >= len(df):\n",
    "            # 如果超出范围，直接添加剩余数据\n",
    "            split_df = df.iloc[start_idx:]\n",
    "            split_df.to_csv(save_path, index=False)\n",
    "            split_info.append({\n",
    "                'split_num': split_num + 1,\n",
    "                'size': len(split_df),\n",
    "                'file_path': save_path\n",
    "            })\n",
    "            break\n",
    "            \n",
    "        # 获取分割点的用户\n",
    "        split_user = df.iloc[end_idx]['serv_number']\n",
    "        \n",
    "        # 向后查找不同用户的位置\n",
    "        while end_idx < len(df) and df.iloc[end_idx]['serv_number'] == split_user:\n",
    "            end_idx += 1\n",
    "            \n",
    "        # 分割并保存数据集\n",
    "        split_df = df.iloc[start_idx:end_idx]\n",
    "        split_df.to_csv(save_path, index=False)\n",
    "        \n",
    "        # 记录分割信息\n",
    "        split_info.append({\n",
    "            'split_num': split_num + 1,\n",
    "            'size': len(split_df),\n",
    "            'file_path': save_path\n",
    "        })\n",
    "        \n",
    "        # 更新开始位置\n",
    "        start_idx = end_idx\n",
    "    \n",
    "    # 打印分割结果信息\n",
    "    print(\"\\n分割完成！分割结果概要：\")\n",
    "    for info in split_info:\n",
    "        print(f\"第 {info['split_num']:02d} 份: {info['size']:,} 条记录 -> {info['file_path']}\")\n",
    "    \n",
    "    # 保存分割信息到日志文件\n",
    "    log_path = os.path.join(save_dir, 'split_info.txt')\n",
    "    with open(log_path, 'w') as f:\n",
    "        f.write(f\"数据分割信息 - 总数据量: {len(df):,} 条\\n\")\n",
    "        f.write(\"=\" * 50 + \"\\n\")\n",
    "        for info in split_info:\n",
    "            f.write(f\"分片 {info['split_num']:02d}:\\n\")\n",
    "            f.write(f\"  记录数: {info['size']:,}\\n\")\n",
    "            f.write(f\"  文件路径: {info['file_path']}\\n\")\n",
    "            f.write(\"-\" * 30 + \"\\n\")\n",
    "    \n",
    "    return split_info\n",
    "\n",
    "# 使用示例\n",
    "if __name__ == \"__main__\":\n",
    "    # 假设df是已经排序的DataFrame\n",
    "    # 进行分割并保存\n",
    "    split_info = split_dataframe(df, num_splits=20)\n",
    "    \n",
    "    print(f\"\\n分割信息已保存到: {os.path.join('/data/zhujianhao/split_data', 'split_info.txt')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datagrand",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
